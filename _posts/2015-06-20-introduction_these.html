---
title: "Reconnaissance de contexte pour l'interaction vocale en habitat intelligent"
category: [blog, these]
icon: /assets/images/posts/these_introduction/init.gif
---

<div class="well">
    Comme promis, une petite introduction pour mieux comprendre mon sujet de thèse et les
    problématiques qui seront abordées.
</div>

<!-- more -->

<h3>De l'informatique ubiquitaire à l'intelligence ambiante</h3>
<p>
Le mot est lâché dès le sujet de thèse&nbsp;; <em>habitat intelligent</em>. Voilà un sujet à la
mode, entre <em>Internet des objets</em> (IoT), smart-watch, smart-home, smart-bidule. Mais
d'abord c'est quoi un habitat intelligent&nbsp;?
</p>
<p>
Sous ce terme, on va regrouper tout ce qui est appartement et maison, mais aussi chambre
médicalisée (en hôpital ou en EHPAD) utilisant le paradigme de l'intelligence ambiante afin
d'apporter de nouveaux services, comme la surveillance, mais aussi le confort. Bon, c'est bien
beau tout ça, mais c'est quoi l'intelligence ambiante&nbsp;?
</p>
<p>
L'intelligence ambiante est un concept qui repose sur celui d'informatique ubiquitaire.
L'informatique ubiquitaire c'est, d'après Weiser, le mec qui l'a défini, la troisième ère de
l'informatique, où les ordinateurs nous entourent de manière quasi-transparente. C'est ce qu'on
appelle communément aujourd'hui l'Internet des objets, quand votre brosse à dent, votre balance,
votre montre ou vos lunettes, sont capable de communiquer avec le monde extérieur, que ce soit
votre smartphone ou directement Internet. Seulement, selon la définition de Weiser, ces objets
sont seulement capable de donner des informations brutes sur leur état&nbsp;; elles ne sont pas
conscientes de leur environnement, de leurs liens avec d'autres objets.
</p>

{% include 10-body/post/05-small-image.html source-url='http://www.parc.com/' image-url='http://www2.parc.com/csl/members/weiser/mw-portrait2.jpg' image-alt='Portrait de Mark Weiser' credit='parc.com' %}

<p>
L'intelligence ambiante, comme je le disais, reprend les concepts de l'informatique ubiquitaire
mais va adjoindre une capacité de traitement de l'information à chacun de ces objets connectés.
Ces objets vont dès lors pouvoir prendre conscience de leur environnement, des liens qui les
lient aux autres objets.
</p>
<p>
Pour clarifier les choses, prenons un exemple&nbsp;:
</p>
<ul>
    <li>à la base, un interrupteur est relié à une lampe. Vous n'avez pas le choix de la lampe
        que vous allumé&nbsp;;</li>
    <li>avec l'informatique ubiquitaire, vous pouvez avoir un interrupteur avec un micro à coté et
        dire <q>Cuisine.</q> en même temps que vous appuyez, pour allumer la lampe de la cuisine
        même si vous êtes à l'autre bout de la maison&nbsp;;</li>
    <li>avec l'intelligence ambiante, plus besoin de ce micro, en appuyant sur l'interrupteur,
        l'ensemble des objets connectés vont communiquer afin de déterminer que la meilleure
        lampe à allumer à cet instant est celle de la cuisine.</li>
</ul>

<h3>Samantha
    <span class="refnote">
        <a href="https://fr.wikipedia.org/wiki/Her">Her (2014)</a>
    </span>, c'est pour 2018</h3>
    <p>
    Comme le laisse présager le titre, la thèse va se découper en deux parties&nbsp;; d'une part la
    reconnaissance de contexte, et l'interaction vocale d'autre part. Nous allons voir que ces deux
    composantes sont fortement liées puisque l'objectif final est de faire en sorte&nbsp;:
    </p>
    <ul>
        <li>que le moment, la forme et le contenu de l'interaction soient dépendant du
            contexte&nbsp;;</li>
        <li>qu'à travers l'interaction, l'utilisateur puisse aider le système à reconnaitre le
            contexte.</li>
    </ul>
    <p>
    Financée par un projet Investissement d'Avenir, ma thèse doit permettre de délivrer en 2018 une
    application smartphone qui reposera sur les travaux que j'aurai réaliser. Pour mettre sur pied
    cette application, le projet regroupe différents collaborateurs, dont notre laboratoire mais
    également plusieurs industriels qui apporteront leur savoir-faire au niveau de la réalisation
    d'application à proprement parlée mais aussi de la génération de données (capteurs) ou du
    traitement de ces données.
    </p>

    {% include 10-body/post/05-small-image.html source-url='http://postscapes.com/internet-of-things-award/project/her/' image-url='http://postscapes.com/internet-of-things-award/wp-content/uploads/2014/01/her-movie.gif' image-alt='Image du film Her où Samantha souhaite une bonne journée' credit='postcapes.com' %}

    <h3>Le contexte est primordial</h3>
    <p>
    Le contexte est un sujet largement traité par de nombreux laboratoires et l'on retrouve en
    général les mêmes problématiques&nbsp;:
    </p>
    <ul>
        <li>Qu'est-ce qu'un contexte&nbsp;?</li>
        <li>Quelles sont les informations nécessaires à la définition d'un contexte&nbsp;?</li>
    </ul>
    <p>
    Toutefois, ces questions sont liées à la notion de contexte en général et non pas
    particulièrement à sa reconnaissance ou son utilisation. De fait, nous utiliserons
    l'état de l'art comme référence sans approfondir outre mesure.
    </p>
    <p>
    Dans notre cas, nous nous intéressons donc davantage à l'utilisation du contexte dans un
    habitat intelligent et nous nous efforcerons de répondre aux questions suivantes&nbsp;:
    </p>
    <ul>
        <li>Quelles sont les informations pertinentes pour reconnaitre un contexte&nbsp;?</li>
        <li>Comment extraire des informations de haut niveau d'un contexte (pour adapter
            l'interaction)&nbsp;?</li>
        <li>Comment découvrir de nouveaux contextes&nbsp;?</li>
    </ul>
    <p>
    C'est questions aussi ont largement été étudiées par différents laboratoires
    <span class="refnote">
        Un peu de bibliographie, sur les projets
        <a href="http://www.eecs.wsu.edu/~cook/pubs/pc03m.ps" rel="nofollow">Mav'Home</a>
        et 
        <a href="http://www.eecs.wsu.edu/~cook/pubs/computer12.pdf" rel="nofollow">C@sas</a>.
    </span> mais également au LIG puisque notre équipe à notamment publié des papiers sur
    la prise de décision en contexte, comme la thèse d'un de mes prédécesseurs soutenue en
    2013
    <span class="refnote">
        La <a href="https://tel.archives-ouvertes.fr/tel-00957941/document" rel="nofollow">thèse de Pedro</a> sur HAL.
    </span>. L'avantage, c'est que durant cette thèse, un corpus à été enregistré, et on va donc
    pouvoir s'en resservir pour nos premières expérimentations, mais j'y reviendrai.
    </p>

    <h3>OK Google, améliorons Siri</h3>
    <p>
    L'objectif du projet, c'est donc d'obtenir une application pour plateforme
    mobile, que ce soit smartphone ou tablette, Android ou iOS. La solution de facilité, ce serait
    d'utiliser les systèmes fournis qui sont à la base de Google Now ou Siri. Mais ces systèmes sont
    de vraies boites noires, ce qui nous pose des problèmes que ce soit éthiques ou techniques. Nous
    nous sommes donc tourné vers une solution tierce.
    </p>
    <p>
    Dans notre cas, nous avons choisis le logiciel <a href="http://cmusphinx.sourceforge.net/" rel="nofollow">Sphinx</a> développé
    par la CMU. Même s'il est un peu moins utilisé aujourd'hui au profit de Kaldi, Sphinx reste une
    alternative de premier choix, largement utilisé et facilement utilisable sur smartphone
    (contrairement à son concurrent).
    </p>
    <p>
    L'utilisation de Sphinx va donc nous permettre d'adapter les différents modèles nécessaires au
    décodage pour correspondre au mieux à notre tâche. Je vous invite à aller voir l'article
    Wikipédia pour un approfondissement des notions de décodage, mais rapidement&nbsp;:
    </p>
    <ul>
        <li>On a un modèle acoustique qui permet de dire <q>Tel signal audio correspond à tel(le)
                son/phonème/syllabe</q>. Les modèles acoustiques disponible sur Internet sont jugés
            trop volumineux pour notre application et on va devoir générer le notre.</li>
        <li>Un dictionnaire de prononciation, ou dictionnaire phonétique, qui liste tous les mots
            connus du système avec leurs différentes prononciation. Si un mot n'est pas dans le
            dictionnaire (mot hors vocabulaire), il ne sera jamais reconnu. Il faut donc un
            dictionnaire recouvrant le plus de mots possible. Dans le cas d'une conversation
            spontanée comme on cherche à le faire, on va se confronter aux mots argotiques, noms
            propres et mots étrangers (comme des titres de chanson, noms de chanteurs, etc.).</li>
        <li>Un modèle de langue qui représente la distribution des mots d'une langue. Concrètement,
            si on a décodé les mots <code>il y</code>, la probabilité que le mot suivant soit
            <code>a</code> est très élevée, et ça va nous permettre de différencier le
            <code>à</code> du <code>a</code>. Un modèle de langue adapté à la tache, est toujours
            plus pertinent qu'un modèle générique, et on va donc essayer d'en générer un.</li>
    </ul>

    {% include 10-body/post/05-small-image.html source-url='http://phdcomics.com/comics/archive.php?comicid=1727' image-url='http://www.phdcomics.com/comics/archive/phd070414s.gif' image-alt='La recherche : le moment où même Google ne sait pas de quoi tu parles' credit='PhD Comics' %}

    <h3>To be continued...</h3>
    <p>
    J'espère vous avoir donné un bon aperçu du travail qui m'attend. Les prochains posts reviendront
    sur les premiers travaux entrepris, et les perspectives évoquées. Si d'ici là vous avez des
    questions, n'hésitez pas à les poser juste en dessous.
    </p>
